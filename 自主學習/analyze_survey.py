# -*- coding: utf-8 -*-
"""
å•å·æ•¸æ“šåˆ†æè…³æœ¬ - æš¨å¤§æ ¡åœ’å°èˆªåŠŸèƒ½é–‹ç™¼å‰æœŸç ”ç©¶
åŠŸèƒ½ï¼šè®€å– CSV å•å·å›è¦†ï¼Œé€²è¡Œçµ±è¨ˆåˆ†æä¸¦ç”¢å‡ºå ±å‘Š
"""

import csv
import json
import os
from collections import Counter, defaultdict
from datetime import datetime
import re

# å–å¾—è…³æœ¬æ‰€åœ¨ç›®éŒ„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))

def load_csv(filepath):
    """è®€å– CSV æª”æ¡ˆ"""
    responses = []
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            responses.append(row)
    return responses

def analyze_demographics(responses):
    """åˆ†æå—è¨ªè€…èƒŒæ™¯"""
    colleges = Counter()
    identities = Counter()
    familiarity = Counter()
    
    for r in responses:
        # å­¸é™¢
        college = r.get('1.è«‹å•æ‚¨çš„å­¸é™¢ï¼å–®ä½æ˜¯ï¼Ÿ', '')
        if college:
            # æ¨™æº–åŒ–å­¸é™¢åç¨±
            if 'ç®¡ç†' in college:
                colleges['ç®¡ç†å­¸é™¢'] += 1
            elif 'ç§‘æŠ€' in college:
                colleges['ç§‘æŠ€å­¸é™¢'] += 1
            elif 'äººæ–‡' in college:
                colleges['äººæ–‡å­¸é™¢'] += 1
            elif 'æ•™è‚²' in college:
                colleges['æ•™è‚²å­¸é™¢'] += 1
            elif 'è­·ç†' in college:
                colleges['è­·ç†å­¸é™¢'] += 1
            elif 'æ™º' in college or 'è¾²' in college:
                colleges['æ™ºæ…§è¾²å­¸é™¢'] += 1
            else:
                colleges[college] += 1
        
        # èº«åˆ†
        identity = r.get('2.è«‹å•æ‚¨çš„èº«åˆ†æ˜¯ï¼Ÿ', '')
        if identity:
            identities[identity] += 1
        
        # ç†Ÿæ‚‰åº¦
        fam = r.get('3.æ‚¨å°æš¨å¤§æ ¡åœ’çš„ç†Ÿæ‚‰ç¨‹åº¦å¦‚ä½•ï¼Ÿ', '')
        if fam:
            familiarity[fam] += 1
    
    return {
        'colleges': dict(colleges),
        'identities': dict(identities),
        'familiarity': dict(familiarity)
    }

def analyze_wayfinding_methods(responses):
    """åˆ†ææ‰¾è·¯æ–¹å¼"""
    methods = Counter()
    
    for r in responses:
        method_str = r.get('1.ç•¶æ‚¨éœ€è¦åœ¨æ ¡åœ’å…§å‰å¾€ä¸€å€‹ã€Œä¸ç†Ÿæ‚‰ã€çš„åœ°é»ï¼ˆå¦‚æŸå€‹æ•™å®¤ã€ç‰¹å®šè¾¦å…¬å®¤ï¼‰æ™‚ï¼Œæ‚¨æœ€å¸¸ä½¿ç”¨ä»¥ä¸‹å“ªç¨®æ–¹å¼ï¼Ÿï¼ˆå¯è¤‡é¸ï¼‰', '')
        if method_str:
            # åˆ†å‰²è¤‡é¸ç­”æ¡ˆ
            for method in method_str.split(', '):
                method = method.strip()
                if method:
                    methods[method] += 1
    
    return dict(methods)

def analyze_map_problems(responses):
    """åˆ†æä½¿ç”¨åœ°åœ– App çš„å•é¡Œ"""
    problems = Counter()
    most_annoying = Counter()
    
    for r in responses:
        # å•é¡Œè¤‡é¸
        prob_str = r.get('2.åœ¨ä½¿ç”¨ Google Maps ç­‰é€šç”¨åœ°åœ– App é€²è¡Œæ ¡åœ’å°èˆªæ™‚ï¼Œæ‚¨æ˜¯å¦æ›¾é‡éä»¥ä¸‹å•é¡Œï¼Ÿï¼ˆå¯è¤‡é¸ï¼‰', '')
        if prob_str:
            for prob in prob_str.split(', '):
                prob = prob.strip()
                if prob:
                    problems[prob] += 1
        
        # æœ€å›°æ“¾å•é¡Œ
        annoying = r.get('3.æ¥çºŒä¸Šé¡Œï¼Œåœ¨æ‚¨å‰›å‰›å‹¾é¸çš„å•é¡Œä¸­ï¼Œå“ªä¸€å€‹æ˜¯ã€Œæœ€è®“æ‚¨å›°æ“¾ã€çš„ï¼Ÿ(è‹¥ä¸Šä¸€é¡Œå›ç­”å…¶ä»–è«‹é¸7)', '')
        if annoying:
            most_annoying[annoying] += 1
    
    return {
        'problems': dict(problems),
        'most_annoying': dict(most_annoying)
    }

def analyze_late_experience(responses):
    """åˆ†æé²åˆ°ç¶“é©—"""
    late = Counter()
    
    for r in responses:
        exp = r.get('4.åœ¨éå»ä¸€å­¸æœŸï¼Œæ‚¨æ˜¯å¦æ›¾å› ã€Œæ‰¾ä¸åˆ°è·¯ã€è€Œå°è‡´ä¸Šèª²ã€é–‹æœƒæˆ–åƒåŠ æ´»å‹•é²åˆ°ï¼Ÿ', '')
        if exp:
            late[exp] += 1
    
    return dict(late)

def find_key_containing(d, substr):
    """æ‰¾åˆ°åŒ…å«ç‰¹å®šå­å­—ä¸²çš„æ¬„ä½åç¨±"""
    for key in d.keys():
        if substr in key:
            return key
    return None

def analyze_desired_features(responses):
    """åˆ†ææœŸæœ›åŠŸèƒ½"""
    features = Counter()
    helpfulness = Counter()
    report_willingness = Counter()
    nps_scores = []
    
    for r in responses:
        # æœŸæœ›åŠŸèƒ½ï¼ˆè¤‡é¸ï¼‰
        feat_key = find_key_containing(r, 'æœ€å¸Œæœ›é€™å€‹ã€Œæ ¡åœ’å°èˆªã€åŠŸèƒ½åŒ…å«')
        feat_str = r.get(feat_key, '') if feat_key else ''
        if feat_str:
            for feat in feat_str.split(', '):
                feat = feat.strip()
                if feat:
                    features[feat] += 1
        
        # å¹«åŠ©ç¨‹åº¦ - ä½¿ç”¨éƒ¨åˆ†åŒ¹é…
        help_key = find_key_containing(r, 'å‡è¨­æˆ‘åœ¨ç¶²ç«™ä¸Šæ¨å‡ºä¸€å€‹')
        help_val = r.get(help_key, '') if help_key else ''
        if help_val:
            helpfulness[help_val] += 1
        
        # å›å ±æ„é¡˜ - ä½¿ç”¨éƒ¨åˆ†åŒ¹é…
        report_key = find_key_containing(r, 'ç‚ºäº†è®“å°èˆªè³‡è¨Šæ°¸é ä¿æŒæœ€æ–°')
        report_val = r.get(report_key, '') if report_key else ''
        if report_val:
            report_willingness[report_val] += 1
        
        # NPS - ä½¿ç”¨éƒ¨åˆ†åŒ¹é…
        nps_key = find_key_containing(r, 'æ‚¨æœ‰å¤šå¤§çš„æ„é¡˜ï¼Œæœƒå°‡é€™å€‹')
        nps_val = r.get(nps_key, '') if nps_key else ''
        if nps_val:
            try:
                nps_scores.append(int(nps_val))
            except:
                pass
    
    # è¨ˆç®— NPS
    promoters = sum(1 for s in nps_scores if s >= 9)
    passives = sum(1 for s in nps_scores if 7 <= s <= 8)
    detractors = sum(1 for s in nps_scores if s <= 6)
    total = len(nps_scores)
    nps = ((promoters - detractors) / total * 100) if total > 0 else 0
    
    return {
        'features': dict(features),
        'helpfulness': dict(helpfulness),
        'report_willingness': dict(report_willingness),
        'nps': {
            'scores': nps_scores,
            'avg': sum(nps_scores) / len(nps_scores) if nps_scores else 0,
            'promoters': promoters,
            'passives': passives,
            'detractors': detractors,
            'nps_score': nps
        }
    }

def analyze_website_usage(responses):
    """åˆ†æç¶²ç«™ä½¿ç”¨æƒ…æ³"""
    usage = Counter()
    
    for r in responses:
        used = r.get('è«‹å•æ‚¨æ˜¯å¦ä½¿ç”¨éæœ¬ç¶²ç«™', '')
        if used:
            usage[used] += 1
    
    return dict(usage)

def extract_qualitative_responses(responses):
    """æå–è³ªæ€§å›ç­”"""
    lost_experiences = []
    urgent_needs = []
    general_suggestions = []
    website_suggestions = []
    contact_info = []
    
    for r in responses:
        # è¿·è·¯ç¶“é©—
        exp = r.get('æ–¹ä¾¿å’Œæˆ‘åˆ†äº«ä¸€æ¬¡æ‚¨åœ¨æ ¡ä¸­å› ç‚ºã€Œä¸ç†Ÿæ‚‰ã€è€Œæ„Ÿåˆ°å›°æ“¾æˆ–è¿·è·¯çš„ç¶“é©—å—ï¼Ÿ', '')
        if exp and exp.strip() and exp.strip() != '-':
            lost_experiences.append(exp.strip())
        
        # ç·Šæ€¥æƒ…æ³éœ€æ±‚
        urgent = r.get('1.æƒ³åƒä¸€ä¸‹ï¼Œä½ åªå‰© 10 åˆ†é˜å°±è¦åœ¨ä¸€é–“ä½ å¾æ²’å»éçš„æ•™å®¤åƒåŠ æœŸæœ«è€ƒã€‚åœ¨é€™ç¨®ç·Šæ€¥æƒ…æ³ä¸‹ï¼Œä½ èªç‚ºä¸€å€‹ç†æƒ³çš„æ ¡åœ’å°èˆªæœ€éœ€è¦æä¾›çµ¦ä½ ä»€éº¼ã€Œé—œéµè³‡è¨Šã€æˆ–ã€ŒåŠŸèƒ½ã€ï¼Ÿ', '')
        if urgent and urgent.strip():
            urgent_needs.append(urgent.strip())
        
        # ä¸€èˆ¬å»ºè­°
        suggestion = r.get('å°æ–¼æ”¹å–„æ ¡åœ’å°‹è·¯é«”é©—ï¼Œæ‚¨æ˜¯å¦æœ‰å…¶ä»–ä»»ä½•å»ºè­°æˆ–æ›¾é‡éçš„å›°æ“¾æƒ³èˆ‡æˆ‘å€‘åˆ†äº«ï¼Ÿï¼ˆé–‹æ”¾å¼å•é¡Œï¼‰', '')
        if suggestion and suggestion.strip() and suggestion.strip() not in ['ç„¡', 'æ²’æœ‰', '-', 'NA', 'åŠ æ²¹']:
            general_suggestions.append(suggestion.strip())
        
        # ç¶²ç«™å»ºè­°
        web_sug = r.get('å°æ–¼ä½¿ç”¨ç¶²ç«™çš„é«”é©—ï¼Œæ‚¨æ˜¯å¦æœ‰å…¶ä»–ä»»ä½•å»ºè­°ä¿®æ”¹/åŠŸèƒ½æ–°å¢ï¼Œæˆ–æ›¾é‡éçš„å›°æ“¾æƒ³èˆ‡æˆ‘å€‘åˆ†äº«ï¼Ÿï¼ˆé–‹æ”¾å¼å•é¡Œï¼‰', '')
        if web_sug and web_sug.strip() and web_sug.strip() not in ['ç„¡', 'æ²’æœ‰', '-', 'NA']:
            website_suggestions.append(web_sug.strip())
        
        # è¯çµ¡è³‡è¨Š
        contact = r.get('æ„Ÿè¬æ‚¨å¡«å¯«å•å·ï¼æˆ‘æ­£åœ¨å°‹æ‰¾é¡˜æ„åƒèˆ‡ 15-20 åˆ†é˜ç·šä¸Šè¨ªè«‡çš„ä½¿ç”¨è€…ï¼Œä»¥æ›´æ·±å…¥åœ°äº†è§£æ‚¨çš„é«”é©—èˆ‡éœ€æ±‚ã€‚è‹¥æ‚¨é¡˜æ„ï¼Œå¯ä»¥ç•™ä¸‹æ‚¨çš„è¯çµ¡æ–¹å¼ï¼ˆEmail æˆ– IGï¼‰ï¼Œæˆ‘å°‡æœƒèˆ‡æ‚¨è¯ç¹«ã€‚ï¼ˆæ­¤ç‚ºé¸å¡«ï¼Œè³‡æ–™å°‡åš´æ ¼ä¿å¯†ï¼‰', '')
        if contact and contact.strip():
            contact_info.append(contact.strip())
    
    return {
        'lost_experiences': lost_experiences,
        'urgent_needs': urgent_needs,
        'general_suggestions': general_suggestions,
        'website_suggestions': website_suggestions,
        'contact_count': len(contact_info)
    }

def categorize_urgent_needs(needs):
    """åˆ†é¡ç·Šæ€¥æƒ…æ³éœ€æ±‚"""
    categories = {
        'ç²¾æº–ä½ç½®/å®¤å…§å®šä½': 0,
        'æœ€çŸ­è·¯å¾‘/æœ€ä½³è·¯ç·š': 0,
        'æ¨“å±¤/å¹³é¢åœ–': 0,
        'é ä¼°æ™‚é–“': 0,
        'æ–¹å‘æŒ‡å¼•': 0,
        'åœ°æ¨™/å»ºç¯‰ç‰©è³‡è¨Š': 0,
        'ARå°èˆª': 0,
        'å…¶ä»–': 0
    }
    
    for need in needs:
        need_lower = need.lower()
        matched = False
        
        if any(kw in need for kw in ['ç²¾æº–', 'ä½ç½®', 'å®šä½', 'å…·é«”', 'è©³ç´°']):
            categories['ç²¾æº–ä½ç½®/å®¤å…§å®šä½'] += 1
            matched = True
        if any(kw in need for kw in ['æœ€çŸ­', 'æœ€å¿«', 'æœ€ä½³', 'è·¯ç·š', 'è·¯å¾‘', 'å°èˆª']):
            categories['æœ€çŸ­è·¯å¾‘/æœ€ä½³è·¯ç·š'] += 1
            matched = True
        if any(kw in need for kw in ['æ¨“å±¤', 'å¹³é¢åœ–', 'å¹¾æ¨“', 'æ¨“']):
            categories['æ¨“å±¤/å¹³é¢åœ–'] += 1
            matched = True
        if any(kw in need for kw in ['æ™‚é–“', 'å¤šä¹…']):
            categories['é ä¼°æ™‚é–“'] += 1
            matched = True
        if any(kw in need for kw in ['æ–¹å‘', 'å¾€å“ª', 'æ€éº¼èµ°', 'è½‰å½']):
            categories['æ–¹å‘æŒ‡å¼•'] += 1
            matched = True
        if any(kw in need for kw in ['åœ°æ¨™', 'å»ºç¯‰', 'å­¸é™¢', 'å“ªè£¡', 'å“ªä¸€æ£Ÿ', 'å¤§æ¨“']):
            categories['åœ°æ¨™/å»ºç¯‰ç‰©è³‡è¨Š'] += 1
            matched = True
        if 'AR' in need or 'ar' in need:
            categories['ARå°èˆª'] += 1
            matched = True
        
        if not matched:
            categories['å…¶ä»–'] += 1
    
    return categories

def generate_report(responses, demographics, wayfinding, problems, late, features, website, qualitative):
    """ç”¢ç”Ÿå®Œæ•´å ±å‘Š"""
    total = len(responses)
    
    # è¨ˆç®—ç™¾åˆ†æ¯”å‡½æ•¸
    def pct(count, total):
        return f"{count} ({count/total*100:.1f}%)" if total > 0 else "0 (0%)"
    
    # æ’åºå­—å…¸
    def sorted_dict(d, reverse=True):
        return dict(sorted(d.items(), key=lambda x: x[1], reverse=reverse))
    
    # è™•ç†æ€¥éœ€åŠŸèƒ½åˆ†é¡
    urgent_categories = categorize_urgent_needs(qualitative['urgent_needs'])
    
    report = f"""# æš¨å¤§æ ¡åœ’å°èˆªåŠŸèƒ½é–‹ç™¼å‰æœŸç ”ç©¶å•å·åˆ†æå ±å‘Š

> **åˆ†ææ—¥æœŸ**ï¼š{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}
> **ç¸½å›è¦†æ•¸**ï¼š{total} ä»½

---

## ğŸ“Š åŸ·è¡Œæ‘˜è¦

æœ¬å•å·èª¿æŸ¥é‡å°æš¨å¤§æ ¡åœ’å°èˆªåŠŸèƒ½çš„é–‹ç™¼éœ€æ±‚é€²è¡Œå‰æœŸç ”ç©¶ï¼Œå…±æ”¶é›† **{total} ä»½æœ‰æ•ˆå›è¦†**ã€‚ä¸»è¦ç™¼ç¾å¦‚ä¸‹ï¼š

### é—œéµæ´å¯Ÿ

1. **ä½¿ç”¨è€…ç—›é»æ˜ç¢º**ï¼šæœ€å¸¸è¦‹å•é¡Œç‚ºã€Œå»ºç¯‰ç‰©åç¨±æ¨™ç¤ºä¸æ¸…ã€èˆ‡ã€Œç„¡æ³•å°èˆªè‡³ç‰¹å®šæ•™å®¤ç·¨è™Ÿã€
2. **é«˜æ¨è–¦æ„é¡˜**ï¼šNPS å¹³å‡åˆ†æ•¸é” **{features['nps']['avg']:.1f}** åˆ†ï¼Œé¡¯ç¤ºä½¿ç”¨è€…å°æ­¤åŠŸèƒ½æœ‰é«˜åº¦æœŸå¾…
3. **åŠŸèƒ½éœ€æ±‚é›†ä¸­**ï¼šã€Œåœ°æ¨™æœå°‹åŠŸèƒ½ã€èˆ‡ã€Œç²¾æº–å®¤å…§å®šä½ã€ç‚ºæœ€å—æœŸæœ›çš„åŠŸèƒ½
4. **ç¶²ç«™ä½¿ç”¨ç‡ä½³**ï¼šç´„ **{website.get('æ˜¯', 0)/total*100:.1f}%** å¡«ç­”è€…å·²ä½¿ç”¨éæœ¬ç¶²ç«™

---

## 1ï¸âƒ£ å—è¨ªè€…èƒŒæ™¯åˆ†æ

### 1.1 å­¸é™¢åˆ†å¸ƒ

| å­¸é™¢ | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for college, count in sorted_dict(demographics['colleges']).items():
        report += f"| {college} | {count} | {count/total*100:.1f}% |\n"
    
    report += f"""
### 1.2 èº«åˆ†åˆ†å¸ƒ

| èº«åˆ† | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for identity, count in sorted_dict(demographics['identities']).items():
        report += f"| {identity} | {count} | {count/total*100:.1f}% |\n"
    
    report += f"""
### 1.3 æ ¡åœ’ç†Ÿæ‚‰ç¨‹åº¦

| ç†Ÿæ‚‰ç¨‹åº¦ | äººæ•¸ | ç™¾åˆ†æ¯” |
|----------|------|--------|
"""
    
    familiarity_order = [
        'å®Œå…¨ä¸ç†Ÿï¼Œæˆ‘æ˜¯æ–°ç”Ÿ/ç¬¬ä¸€æ¬¡ä¾†',
        'ä¸å¤ªç†Ÿï¼Œç¶“å¸¸éœ€è¦æ‰¾è·¯',
        'æ™®é€šï¼Œåªç†Ÿæ‚‰è‡ªå·±å­¸é™¢å’Œå¸¸å»çš„å¹¾å€‹åœ°æ–¹',
        'ç†Ÿæ‚‰ï¼ŒçŸ¥é“å¤§éƒ¨åˆ†ä¸»è¦å»ºç¯‰å’Œè·¯ç·š',
        'éå¸¸ç†Ÿæ‚‰ï¼Œå¹¾ä¹æ¯å€‹è§’è½éƒ½çŸ¥é“'
    ]
    
    for fam in familiarity_order:
        count = demographics['familiarity'].get(fam, 0)
        if count > 0:
            report += f"| {fam} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
> [!NOTE]
> å¤§å¤šæ•¸å—è¨ªè€…ï¼ˆ{demographics['familiarity'].get('æ™®é€šï¼Œåªç†Ÿæ‚‰è‡ªå·±å­¸é™¢å’Œå¸¸å»çš„å¹¾å€‹åœ°æ–¹', 0) + demographics['familiarity'].get('ç†Ÿæ‚‰ï¼ŒçŸ¥é“å¤§éƒ¨åˆ†ä¸»è¦å»ºç¯‰å’Œè·¯ç·š', 0)} äººï¼‰å°æ ¡åœ’æœ‰ä¸€å®šç†Ÿæ‚‰åº¦ï¼Œä½†ä»æœ‰æ˜é¡¯çš„å°èˆªéœ€æ±‚ã€‚

---

## 2ï¸âƒ£ å°‹è·¯è¡Œç‚ºåˆ†æ

### 2.1 å¸¸ç”¨å°‹è·¯æ–¹å¼ï¼ˆè¤‡é¸ï¼‰

| æ–¹å¼ | æ¬¡æ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for method, count in sorted_dict(wayfinding).items():
        short_method = method[:50] + '...' if len(method) > 50 else method
        report += f"| {short_method} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
### 2.2 ä½¿ç”¨åœ°åœ– App é‡åˆ°çš„å•é¡Œï¼ˆè¤‡é¸ï¼‰

| å•é¡Œ | æ¬¡æ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for prob, count in sorted_dict(problems['problems']).items():
        short_prob = prob[:60] + '...' if len(prob) > 60 else prob
        report += f"| {short_prob} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
### 2.3 æœ€å›°æ“¾çš„å•é¡Œ

| é¸é … | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    problem_mapping = {
        '1': 'å»ºç¯‰ç‰©åç¨±æ¨™ç¤ºä¸æ¸…æˆ–éŒ¯èª¤',
        '2': 'ç„¡æ³•å°èˆªè‡³ç‰¹å®šæ•™å®¤ç·¨è™Ÿ',
        '3': 'æ­¥è¡Œè·¯ç·šå¾ˆç¹è·¯ï¼Œä¸æ˜¯æœ€ä½³æ·å¾‘',
        '4': 'å°èˆªåˆ°å®¤å¤–å°±çµæŸï¼Œç„¡æ³•æŒ‡å¼•é€²å…¥å»ºç¯‰ç‰©',
        '5': 'å®šä½ä¸æº–ç¢ºï¼Œä½ç½®é£„ç§»',
        '6': 'å¾ˆå°‘ä½¿ç”¨æˆ–æ²’é‡éå•é¡Œ',
        '7': 'å…¶ä»–'
    }
    
    for key, count in sorted_dict(problems['most_annoying']).items():
        desc = problem_mapping.get(key, key)
        report += f"| {key}. {desc} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
> [!IMPORTANT]
> **ã€Œç„¡æ³•å°èˆªè‡³ç‰¹å®šæ•™å®¤ç·¨è™Ÿã€** å’Œ **ã€Œå»ºç¯‰ç‰©åç¨±æ¨™ç¤ºä¸æ¸…ã€** æ˜¯æœ€ä¸»è¦çš„ç—›é»ï¼Œä½”æ¯”è¶…é 50%ï¼Œé€™æ‡‰è©²æ˜¯é–‹ç™¼çš„é¦–è¦è§£æ±ºç›®æ¨™ã€‚

---

## 3ï¸âƒ£ é²åˆ°ç¶“é©—åˆ†æ

| ç¶“é©— | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for exp, count in sorted_dict(late).items():
        report += f"| {exp} | {count} | {count/total*100:.1f}% |\n"

    late_happened = late.get('å¶çˆ¾ç™¼ç”Ÿ', 0)
    report += f"""
> [!WARNING]
> ç´„ **{late_happened}** äººï¼ˆ{late_happened/total*100:.1f}%ï¼‰æ›¾å› æ‰¾ä¸åˆ°è·¯è€Œé²åˆ°ï¼Œé€™èªªæ˜å°èˆªåŠŸèƒ½æœ‰å¯¦éš›çš„ä½¿ç”¨éœ€æ±‚ã€‚

---

## 4ï¸âƒ£ åŠŸèƒ½éœ€æ±‚åˆ†æ

### 4.1 æœ€æœŸæœ›çš„åŠŸèƒ½ï¼ˆè¤‡é¸ï¼Œæœ€å¤š3é …ï¼‰

| åŠŸèƒ½ | æ¬¡æ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for feat, count in sorted_dict(features['features']).items():
        short_feat = feat[:50] + '...' if len(feat) > 50 else feat
        report += f"| {short_feat} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
### 4.2 ç·Šæ€¥æƒ…æ³éœ€æ±‚åˆ†é¡

æ ¹æ“šé–‹æ”¾é¡Œå›ç­”ã€Œ10åˆ†é˜å…§è¶•åˆ°æœŸæœ«è€ƒæ•™å®¤ï¼Œæœ€éœ€è¦ä»€éº¼åŠŸèƒ½ã€çš„åˆ†æï¼š

| éœ€æ±‚é¡åˆ¥ | æ¬¡æ•¸ |
|----------|------|
"""
    
    for cat, count in sorted_dict(urgent_categories).items():
        if count > 0:
            report += f"| {cat} | {count} |\n"

    report += f"""
> [!TIP]
> ä½¿ç”¨è€…åœ¨ç·Šæ€¥æƒ…æ³ä¸‹æœ€éœ€è¦çš„æ˜¯**ç²¾æº–çš„ä½ç½®è³‡è¨Š**èˆ‡**æœ€çŸ­è·¯å¾‘è¦åŠƒ**ï¼Œé–‹ç™¼æ™‚æ‡‰å„ªå…ˆç¢ºä¿é€™å…©é …åŠŸèƒ½çš„å¯é æ€§ã€‚

---

## 5ï¸âƒ£ åŠŸèƒ½è©•åƒ¹åˆ†æ

### 5.1 é æœŸå¹«åŠ©ç¨‹åº¦ï¼ˆ1-5åˆ†ï¼‰

| è©•åˆ† | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for score, count in sorted(features['helpfulness'].items(), key=lambda x: x[0], reverse=True):
        report += f"| {score} åˆ† | {count} | {count/total*100:.1f}% |\n"

    high_help = features['helpfulness'].get('5', 0) + features['helpfulness'].get('4', 0)
    report += f"""
> èªç‚ºã€Œæœ‰å¹«åŠ©ã€æˆ–ã€Œéå¸¸æœ‰å¹«åŠ©ã€çš„æ¯”ä¾‹ï¼š**{high_help/total*100:.1f}%**

### 5.2 éŒ¯èª¤å›å ±æ„é¡˜ï¼ˆ1-5åˆ†ï¼‰

| è©•åˆ† | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for score, count in sorted(features['report_willingness'].items(), key=lambda x: x[0]):
        report += f"| {score} åˆ† | {count} | {count/total*100:.1f}% |\n"

    low_willingness = features['report_willingness'].get('1', 0) + features['report_willingness'].get('2', 0)
    report += f"""
> [!NOTE]
> ç´„ **{low_willingness/total*100:.1f}%** çš„ä½¿ç”¨è€…è¡¨ç¤ºã€Œéå¸¸é¡˜æ„ã€æˆ–ã€Œé¡˜æ„ã€å›å ±éŒ¯èª¤ï¼Œå¯è€ƒæ…®è¨­è¨ˆç°¡æ˜“çš„å›å ±æ©Ÿåˆ¶ã€‚

### 5.3 NPSï¼ˆNet Promoter Scoreï¼‰åˆ†æ

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| å¹³å‡æ¨è–¦åˆ†æ•¸ | **{features['nps']['avg']:.1f}** / 10 |
| æ¨è–¦è€… (9-10åˆ†) | {features['nps']['promoters']} äºº |
| è¢«å‹•è€… (7-8åˆ†) | {features['nps']['passives']} äºº |
| è²¶æè€… (0-6åˆ†) | {features['nps']['detractors']} äºº |
| **NPS åˆ†æ•¸** | **{features['nps']['nps_score']:.1f}** |

> [!TIP]
> NPS åˆ†æ•¸ {features['nps']['nps_score']:.1f} è¡¨ç¤ºä½¿ç”¨è€…å°æ­¤åŠŸèƒ½æœ‰{'é«˜åº¦' if features['nps']['nps_score'] > 30 else 'ä¸­åº¦' if features['nps']['nps_score'] > 0 else 'ä½åº¦'}æ¨è–¦æ„é¡˜ã€‚

---

## 6ï¸âƒ£ ç¶²ç«™ä½¿ç”¨æƒ…æ³

| é …ç›® | äººæ•¸ | ç™¾åˆ†æ¯” |
|------|------|--------|
"""
    
    for item, count in website.items():
        report += f"| {item} | {count} | {count/total*100:.1f}% |\n"

    report += f"""
---

## 7ï¸âƒ£ è³ªæ€§åˆ†æ

### 7.1 è¿·è·¯ç¶“é©—æ‘˜è¦

å…±æ”¶é›†åˆ° **{len(qualitative['lost_experiences'])}** å‰‡è¿·è·¯ç¶“é©—åˆ†äº«ï¼Œä¸»è¦é¡å‹åŒ…æ‹¬ï¼š

"""
    
    if qualitative['lost_experiences']:
        for i, exp in enumerate(qualitative['lost_experiences'][:10], 1):
            exp_short = exp[:100] + '...' if len(exp) > 100 else exp
            report += f"- {exp_short}\n"
        if len(qualitative['lost_experiences']) > 10:
            report += f"\n*ï¼ˆé‚„æœ‰ {len(qualitative['lost_experiences']) - 10} å‰‡å›è¦†...ï¼‰*\n"

    report += f"""
### 7.2 æ”¹å–„æ ¡åœ’å°‹è·¯å»ºè­°

å…±æ”¶é›†åˆ° **{len(qualitative['general_suggestions'])}** å‰‡å»ºè­°ï¼š

"""
    
    if qualitative['general_suggestions']:
        for sug in qualitative['general_suggestions']:
            sug_short = sug[:150] + '...' if len(sug) > 150 else sug
            report += f"- {sug_short}\n"

    report += f"""
### 7.3 ç¶²ç«™åŠŸèƒ½å»ºè­°

å…±æ”¶é›†åˆ° **{len(qualitative['website_suggestions'])}** å‰‡é‡å°ç¶²ç«™çš„å»ºè­°ï¼š

"""
    
    if qualitative['website_suggestions']:
        for sug in qualitative['website_suggestions']:
            sug_short = sug[:150] + '...' if len(sug) > 150 else sug
            report += f"- {sug_short}\n"

    report += f"""
---

## 8ï¸âƒ£ çµè«–èˆ‡å»ºè­°

### é–‹ç™¼å„ªå…ˆé †åºå»ºè­°

æ ¹æ“šå•å·åˆ†æçµæœï¼Œå»ºè­°ä»¥ä¸‹é–‹ç™¼å„ªå…ˆé †åºï¼š

1. **ğŸ”´ é«˜å„ªå…ˆç´š**
   - åœ°æ¨™æœå°‹åŠŸèƒ½ï¼šå¯ç”¨æ•™å®¤ç·¨è™Ÿï¼ˆå¦‚ A100ï¼‰ã€å»ºç¯‰ç‰©åç¨±æˆ–è¾¦å…¬å®¤åç¨±æœå°‹
   - ç²¾æº–çš„å®¤å…§å®šä½ï¼šèƒ½æŒ‡å¼•åˆ°ç‰¹å®šæ•™å®¤é–€å£
   - æœ€ä½³åŒ–è·¯å¾‘ï¼šæä¾›æœ€å¿«ã€æœ€çŸ­çš„æ­¥è¡Œæ·å¾‘

2. **ğŸŸ¡ ä¸­å„ªå…ˆç´š**
   - é ä¼°æ­¥è¡Œæ™‚é–“
   - å‘¨é‚Šè¨­æ–½æ¨™ç¤ºï¼ˆå»æ‰€ã€é£²æ°´æ©Ÿã€å½±å°æ©Ÿã€è²©è³£æ©Ÿç­‰ï¼‰
   - æ¨“å±¤å¹³é¢åœ–

3. **ğŸŸ¢ ä½å„ªå…ˆç´š**
   - ç„¡éšœç¤™è·¯ç·š
   - éŒ¯èª¤å›å ±æ©Ÿåˆ¶
   - AR å°èˆª

### è¨ªè«‡æ„é¡˜

å…±æœ‰ **{qualitative['contact_count']}** ä½å¡«ç­”è€…é¡˜æ„åƒèˆ‡å¾ŒçºŒè¨ªè«‡ï¼Œå¯é€²ä¸€æ­¥é€²è¡Œæ·±åº¦è¨ªè«‡ä»¥ç²å–æ›´è©³ç´°çš„éœ€æ±‚è³‡è¨Šã€‚

---

*å ±å‘Šç”¢ç”Ÿæ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    return report

def main():
    # è®€å–è³‡æ–™ - ä½¿ç”¨è…³æœ¬æ‰€åœ¨ç›®éŒ„çš„çµ•å°è·¯å¾‘
    csv_filename = 'ã€Œæš¨å¤§æ ¡åœ’å°èˆªã€åŠŸèƒ½é–‹ç™¼å‰æœŸç ”ç©¶å•å· (å›è¦†) - è¡¨å–®å›æ‡‰ 1.csv'
    filepath = os.path.join(SCRIPT_DIR, csv_filename)
    responses = load_csv(filepath)
    
    print(f"è¼‰å…¥ {len(responses)} ç­†å›è¦†è³‡æ–™")
    
    # é€²è¡Œåˆ†æ
    demographics = analyze_demographics(responses)
    wayfinding = analyze_wayfinding_methods(responses)
    problems = analyze_map_problems(responses)
    late = analyze_late_experience(responses)
    features = analyze_desired_features(responses)
    website = analyze_website_usage(responses)
    qualitative = extract_qualitative_responses(responses)
    
    # ç”¢ç”Ÿå ±å‘Š
    report = generate_report(
        responses, demographics, wayfinding, problems, 
        late, features, website, qualitative
    )
    
    # å„²å­˜å ±å‘Š - ä½¿ç”¨è…³æœ¬æ‰€åœ¨ç›®éŒ„
    report_path = os.path.join(SCRIPT_DIR, 'å•å·åˆ†æå ±å‘Š.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"å ±å‘Šå·²å„²å­˜è‡³ï¼š{report_path}")
    
    # è¼¸å‡º JSON æ•¸æ“šï¼ˆä¾›å¾ŒçºŒè™•ç†ï¼‰
    data = {
        'total_responses': len(responses),
        'demographics': demographics,
        'wayfinding': wayfinding,
        'problems': problems,
        'late_experience': late,
        'desired_features': features,
        'website_usage': website,
        'qualitative_counts': {
            'lost_experiences': len(qualitative['lost_experiences']),
            'urgent_needs': len(qualitative['urgent_needs']),
            'general_suggestions': len(qualitative['general_suggestions']),
            'website_suggestions': len(qualitative['website_suggestions']),
            'contact_count': qualitative['contact_count']
        }
    }
    
    json_path = os.path.join(SCRIPT_DIR, 'å•å·åˆ†ææ•¸æ“š.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"JSON æ•¸æ“šå·²å„²å­˜è‡³ï¼š{json_path}")

if __name__ == '__main__':
    main()
